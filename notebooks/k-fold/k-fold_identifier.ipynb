{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from model import BertCustomBinaryClassifier\n",
    "from utils.ensemble_utils import make_predictions\n",
    "from utils.evaluate_metrics import evaluate_metrics\n",
    "from utils.data_preprocessing import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"transforkmer_values.modeling_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"\")\n",
    "parser.add_argument(\"--max_length\", type=int, default=200, help=\"\")\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5-fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5\n",
      "Identifier model date: 2025-02-27\n",
      "Number of folds: 5\n",
      "\n",
      "Processing 3-mer:\n",
      "Validation 3-mer - Fold 1: ACC=0.8939, SN=0.8253, SP=0.9603, MCC=0.7943, AUC=0.8925\n",
      "Validation 3-mer - Fold 2: ACC=0.8822, SN=0.8201, SP=0.9410, MCC=0.7685, AUC=0.8837\n",
      "Validation 3-mer - Fold 3: ACC=0.9158, SN=0.8810, SP=0.9541, MCC=0.8346, AUC=0.9073\n",
      "Validation 3-mer - Fold 4: ACC=0.9140, SN=0.8850, SP=0.9412, MCC=0.8286, AUC=0.9237\n",
      "Validation 3-mer - Fold 5: ACC=0.8938, SN=0.8262, SP=0.9653, MCC=0.7966, AUC=0.9017\n",
      "\n",
      "\n",
      "Processing 4-mer:\n",
      "Validation 4-mer - Fold 1: ACC=0.8939, SN=0.8356, SP=0.9503, MCC=0.7923, AUC=0.9043\n",
      "Validation 4-mer - Fold 2: ACC=0.8973, SN=0.8339, SP=0.9574, MCC=0.7994, AUC=0.9202\n",
      "Validation 4-mer - Fold 3: ACC=0.9057, SN=0.8521, SP=0.9647, MCC=0.8181, AUC=0.9074\n",
      "Validation 4-mer - Fold 4: ACC=0.9292, SN=0.8885, SP=0.9673, MCC=0.8603, AUC=0.9385\n",
      "Validation 4-mer - Fold 5: ACC=0.9073, SN=0.8426, SP=0.9757, MCC=0.8229, AUC=0.9162\n",
      "\n",
      "\n",
      "Processing 5-mer:\n",
      "Validation 5-mer - Fold 1: ACC=0.8906, SN=0.8425, SP=0.9371, MCC=0.7840, AUC=0.9144\n",
      "Validation 5-mer - Fold 2: ACC=0.8754, SN=0.8097, SP=0.9377, MCC=0.7555, AUC=0.8876\n",
      "Validation 5-mer - Fold 3: ACC=0.8788, SN=0.8103, SP=0.9541, MCC=0.7680, AUC=0.8996\n",
      "Validation 5-mer - Fold 4: ACC=0.8887, SN=0.8293, SP=0.9444, MCC=0.7810, AUC=0.9292\n",
      "Validation 5-mer - Fold 5: ACC=0.8904, SN=0.8230, SP=0.9618, MCC=0.7898, AUC=0.9133\n",
      "\n",
      "\n",
      "Processing 6-mer:\n",
      "Validation 6-mer - Fold 1: ACC=0.8687, SN=0.8048, SP=0.9305, MCC=0.7423, AUC=0.8843\n",
      "Validation 6-mer - Fold 2: ACC=0.8687, SN=0.7785, SP=0.9541, MCC=0.7468, AUC=0.8893\n",
      "Validation 6-mer - Fold 3: ACC=0.8872, SN=0.8232, SP=0.9576, MCC=0.7836, AUC=0.9001\n",
      "Validation 6-mer - Fold 4: ACC=0.8803, SN=0.8014, SP=0.9542, MCC=0.7674, AUC=0.9102\n",
      "Validation 6-mer - Fold 5: ACC=0.8735, SN=0.7803, SP=0.9722, MCC=0.7634, AUC=0.8987\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.50\n",
    "num_folds = 5\n",
    "kmer_values = [3, 4, 5, 6]\n",
    "model_date = \"2025-02-27_V1\"\n",
    "train_predictions_list, test_predictions_list = [], []\n",
    "train_labels_list, test_labels_list = [], []\n",
    "\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Identifier model date: {model_date}\")\n",
    "print(f\"Number of folds: {num_folds}\\n\")\n",
    "\n",
    "results = []\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)  \n",
    "\n",
    "for kmer in kmer_values:\n",
    "    args.model_path = f\"./outputs/identifier_models/{model_date}/{kmer}-mer\"\n",
    "    args.train_data_path = f\"./data/enhancer_identification/{kmer}-mer_identification_train.txt\"\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(args, validation=False)\n",
    "    dataset_size = len(dataset)\n",
    "    dataset_indices = np.arange(dataset_size)\n",
    "\n",
    "    print(f\"Processing {kmer}-mer:\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset_indices)): \n",
    "        # Create train and validation subsets\n",
    "        train_subset = [dataset[i] for i in train_idx]\n",
    "        val_subset = [dataset[i] for i in val_idx]\n",
    "\n",
    "        # Create data loaders\n",
    "        train_dataloader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=False)\n",
    "        val_dataloader = DataLoader(val_subset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "        # Model\n",
    "        model = BertCustomBinaryClassifier.from_pretrained(args.model_path, num_labels=1).to(device)\n",
    "\n",
    "        # Train dataset prediction\n",
    "        train_predictions, train_labels = make_predictions(model, train_dataloader, kmer=kmer)\n",
    "        train_predictions_list.append(train_predictions)\n",
    "        train_labels_list.append(train_labels)\n",
    "\n",
    "        acc, sn, sp, mcc, auc = evaluate_metrics(train_predictions, train_labels)\n",
    "        results.append({\"k-mer\": kmer, \"Fold\": fold + 1, \"Dataset\": \"Train\", \n",
    "                        \"Accuracy\": acc, \"Sensitivity\": sn, \"Specificity\": sp, \"MCC\": mcc, \"AUC\": auc})\n",
    "        \n",
    "        # Validation dataset prediction\n",
    "        val_predictions, val_labels = make_predictions(model, val_dataloader, kmer=kmer)\n",
    "        test_predictions_list.append(val_predictions)\n",
    "        test_labels_list.append(val_labels)\n",
    "\n",
    "        acc, sn, sp, mcc, auc = evaluate_metrics(val_predictions, val_labels)\n",
    "        results.append({\"k-mer\": kmer, \"Fold\": fold + 1, \"Dataset\": \"Validation\", \n",
    "                        \"Accuracy\": acc, \"Sensitivity\": sn, \"Specificity\": sp, \"MCC\": mcc, \"AUC\": auc})\n",
    "        \n",
    "        print(f\"Validation {kmer}-mer - Fold {fold + 1}: ACC={acc:.4f}, SN={sn:.4f}, SP={sp:.4f}, MCC={mcc:.4f}, AUC={auc:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_5_df = pd.DataFrame(results, columns=[\"k-mer\", \"Dataset\", \"Fold\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"MCC\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold training results:\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset   |   Fold |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+===========+========+============+===============+===============+========+========+\n",
      "|       3 | Train     |      1 |     0.9014 |        0.8532 |        0.9501 | 0.8068 | 0.9037 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      2 |     0.9044 |        0.8544 |        0.9550 | 0.8131 | 0.9059 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      3 |     0.8960 |        0.8389 |        0.9517 | 0.7965 | 0.9000 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      4 |     0.8964 |        0.8388 |        0.9550 | 0.7986 | 0.8964 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      5 |     0.9015 |        0.8533 |        0.9490 | 0.8064 | 0.9018 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      1 |     0.9099 |        0.8540 |        0.9662 | 0.8251 | 0.9206 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      2 |     0.9090 |        0.8544 |        0.9644 | 0.8233 | 0.9167 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      3 |     0.9069 |        0.8500 |        0.9625 | 0.8186 | 0.9198 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      4 |     0.9011 |        0.8413 |        0.9618 | 0.8083 | 0.9123 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      5 |     0.9065 |        0.8524 |        0.9599 | 0.8175 | 0.9176 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      1 |     0.8833 |        0.8180 |        0.9492 | 0.7736 | 0.9070 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      2 |     0.8871 |        0.8259 |        0.9491 | 0.7805 | 0.9135 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      3 |     0.8863 |        0.8261 |        0.9450 | 0.7775 | 0.9106 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      4 |     0.8838 |        0.8212 |        0.9474 | 0.7742 | 0.9034 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      5 |     0.8834 |        0.8227 |        0.9431 | 0.7720 | 0.9072 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      1 |     0.8774 |        0.7961 |        0.9594 | 0.7654 | 0.8994 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      2 |     0.8774 |        0.8025 |        0.9534 | 0.7640 | 0.8980 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      3 |     0.8728 |        0.7911 |        0.9525 | 0.7546 | 0.8952 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      4 |     0.8745 |        0.7970 |        0.9533 | 0.7589 | 0.8929 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      5 |     0.8762 |        0.8024 |        0.9490 | 0.7602 | 0.8957 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "training_5_df = results_5_df[results_5_df['Dataset'].str.contains(\"Train\")]\n",
    "print(f\"{num_folds}-fold training results:\")\n",
    "print(tabulate(training_5_df, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation results:\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset    |   Fold |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+============+========+============+===============+===============+========+========+\n",
      "|       3 | Validation |      1 |     0.8939 |        0.8253 |        0.9603 | 0.7943 | 0.8925 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      2 |     0.8822 |        0.8201 |        0.9410 | 0.7685 | 0.8837 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      3 |     0.9158 |        0.8810 |        0.9541 | 0.8346 | 0.9073 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      4 |     0.9140 |        0.8850 |        0.9412 | 0.8286 | 0.9237 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      5 |     0.8938 |        0.8262 |        0.9653 | 0.7966 | 0.9017 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      1 |     0.8939 |        0.8356 |        0.9503 | 0.7923 | 0.9043 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      2 |     0.8973 |        0.8339 |        0.9574 | 0.7994 | 0.9202 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      3 |     0.9057 |        0.8521 |        0.9647 | 0.8181 | 0.9074 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      4 |     0.9292 |        0.8885 |        0.9673 | 0.8603 | 0.9385 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      5 |     0.9073 |        0.8426 |        0.9757 | 0.8229 | 0.9162 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      1 |     0.8906 |        0.8425 |        0.9371 | 0.7840 | 0.9144 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      2 |     0.8754 |        0.8097 |        0.9377 | 0.7555 | 0.8876 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      3 |     0.8788 |        0.8103 |        0.9541 | 0.7680 | 0.8996 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      4 |     0.8887 |        0.8293 |        0.9444 | 0.7810 | 0.9292 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      5 |     0.8904 |        0.8230 |        0.9618 | 0.7898 | 0.9133 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      1 |     0.8687 |        0.8048 |        0.9305 | 0.7423 | 0.8843 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      2 |     0.8687 |        0.7785 |        0.9541 | 0.7468 | 0.8893 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      3 |     0.8872 |        0.8232 |        0.9576 | 0.7836 | 0.9001 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      4 |     0.8803 |        0.8014 |        0.9542 | 0.7674 | 0.9102 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      5 |     0.8735 |        0.7803 |        0.9722 | 0.7634 | 0.8987 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "validation_5_df = results_5_df[results_5_df['Dataset'].str.contains(\"Validation\")]\n",
    "print(f\"{num_folds}-fold validation results:\")\n",
    "print(tabulate(validation_5_df, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-fold training results:\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset   |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+===========+============+===============+===============+========+========+\n",
      "|       3 | Train     |     0.8999 |        0.8477 |        0.9522 | 0.8043 | 0.9015 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |     0.9067 |        0.8504 |        0.9629 | 0.8185 | 0.9174 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |     0.8848 |        0.8228 |        0.9468 | 0.7755 | 0.9083 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |     0.8757 |        0.7978 |        0.9535 | 0.7606 | 0.8963 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "\n",
      "Average 5-fold validation results:\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset    |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+============+============+===============+===============+========+========+\n",
      "|       3 | Validation |     0.8999 |        0.8475 |        0.9524 | 0.8045 | 0.9018 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |     0.9067 |        0.8505 |        0.9631 | 0.8186 | 0.9173 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |     0.8848 |        0.8229 |        0.9470 | 0.7756 | 0.9088 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |     0.8757 |        0.7976 |        0.9537 | 0.7607 | 0.8965 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate average metrics for each k-mer across the k folds\n",
    "average_5_results = results_5_df.groupby(['k-mer', 'Dataset']).mean(numeric_only=True).reset_index()\n",
    "average_5_results = average_5_results.drop(columns=['Fold'])\n",
    "\n",
    "average_training_5_results = average_5_results[average_5_results['Dataset'].str.contains(\"Train\")]\n",
    "average_validation_5_results = average_5_results[average_5_results['Dataset'].str.contains(\"Validation\")]\n",
    "\n",
    "print(f\"Average {num_folds}-fold training results:\")\n",
    "print(tabulate(average_training_5_results, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))\n",
    "\n",
    "print(f\"\\nAverage {num_folds}-fold validation results:\")\n",
    "print(tabulate(average_validation_5_results, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10-fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5\n",
      "Identifier model date: 2025-02-27\n",
      "Number of folds: 10\n",
      "\n",
      "Processing 3-mer:\n",
      "Validation 3-mer - Fold 1: ACC=0.8788, SN=0.8176, SP=0.9396, MCC=0.7631, AUC=0.8754\n",
      "Validation 3-mer - Fold 2: ACC=0.9091, SN=0.8333, SP=0.9804, MCC=0.8256, AUC=0.9107\n",
      "Validation 3-mer - Fold 3: ACC=0.8822, SN=0.8176, SP=0.9463, MCC=0.7705, AUC=0.8786\n",
      "Validation 3-mer - Fold 4: ACC=0.8822, SN=0.8227, SP=0.9359, MCC=0.7665, AUC=0.8908\n",
      "Validation 3-mer - Fold 5: ACC=0.9327, SN=0.9091, SP=0.9580, MCC=0.8667, AUC=0.9312\n",
      "Validation 3-mer - Fold 6: ACC=0.8990, SN=0.8535, SP=0.9500, MCC=0.8032, AUC=0.8830\n",
      "Validation 3-mer - Fold 7: ACC=0.9158, SN=0.8865, SP=0.9423, MCC=0.8317, AUC=0.9302\n",
      "Validation 3-mer - Fold 8: ACC=0.9125, SN=0.8836, SP=0.9404, MCC=0.8259, AUC=0.9184\n",
      "Validation 3-mer - Fold 9: ACC=0.9088, SN=0.8440, SP=0.9677, MCC=0.8217, AUC=0.9192\n",
      "Validation 3-mer - Fold 10: ACC=0.8784, SN=0.8110, SP=0.9621, MCC=0.7703, AUC=0.8864\n",
      "\n",
      "\n",
      "Processing 4-mer:\n",
      "Validation 4-mer - Fold 1: ACC=0.8889, SN=0.8243, SP=0.9530, MCC=0.7841, AUC=0.8926\n",
      "Validation 4-mer - Fold 2: ACC=0.8990, SN=0.8472, SP=0.9477, MCC=0.8008, AUC=0.9158\n",
      "Validation 4-mer - Fold 3: ACC=0.9158, SN=0.8514, SP=0.9799, MCC=0.8385, AUC=0.9328\n",
      "Validation 4-mer - Fold 4: ACC=0.8788, SN=0.8156, SP=0.9359, MCC=0.7601, AUC=0.9077\n",
      "Validation 4-mer - Fold 5: ACC=0.9125, SN=0.8571, SP=0.9720, MCC=0.8316, AUC=0.9139\n",
      "Validation 4-mer - Fold 6: ACC=0.8990, SN=0.8471, SP=0.9571, MCC=0.8046, AUC=0.9012\n",
      "Validation 4-mer - Fold 7: ACC=0.9327, SN=0.8936, SP=0.9679, MCC=0.8665, AUC=0.9436\n",
      "Validation 4-mer - Fold 8: ACC=0.9259, SN=0.8836, SP=0.9669, MCC=0.8544, AUC=0.9341\n",
      "Validation 4-mer - Fold 9: ACC=0.9257, SN=0.8794, SP=0.9677, MCC=0.8533, AUC=0.9150\n",
      "Validation 4-mer - Fold 10: ACC=0.8885, SN=0.8110, SP=0.9848, MCC=0.7942, AUC=0.9175\n",
      "\n",
      "\n",
      "Processing 5-mer:\n",
      "Validation 5-mer - Fold 1: ACC=0.8956, SN=0.8514, SP=0.9396, MCC=0.7942, AUC=0.9247\n",
      "Validation 5-mer - Fold 2: ACC=0.8855, SN=0.8333, SP=0.9346, MCC=0.7736, AUC=0.9038\n",
      "Validation 5-mer - Fold 3: ACC=0.8788, SN=0.8041, SP=0.9530, MCC=0.7659, AUC=0.9025\n",
      "Validation 5-mer - Fold 4: ACC=0.8721, SN=0.8156, SP=0.9231, MCC=0.7456, AUC=0.8733\n",
      "Validation 5-mer - Fold 5: ACC=0.8889, SN=0.8312, SP=0.9510, MCC=0.7849, AUC=0.9141\n",
      "Validation 5-mer - Fold 6: ACC=0.8687, SN=0.7898, SP=0.9571, MCC=0.7516, AUC=0.8882\n",
      "Validation 5-mer - Fold 7: ACC=0.8990, SN=0.8511, SP=0.9423, MCC=0.7993, AUC=0.9361\n",
      "Validation 5-mer - Fold 8: ACC=0.8788, SN=0.8082, SP=0.9470, MCC=0.7640, AUC=0.9228\n",
      "Validation 5-mer - Fold 9: ACC=0.9155, SN=0.8723, SP=0.9548, MCC=0.8324, AUC=0.9230\n",
      "Validation 5-mer - Fold 10: ACC=0.8649, SN=0.7805, SP=0.9697, MCC=0.7502, AUC=0.9058\n",
      "\n",
      "\n",
      "Processing 6-mer:\n",
      "Validation 6-mer - Fold 1: ACC=0.8586, SN=0.7838, SP=0.9329, MCC=0.7250, AUC=0.8826\n",
      "Validation 6-mer - Fold 2: ACC=0.8788, SN=0.8264, SP=0.9281, MCC=0.7601, AUC=0.8857\n",
      "Validation 6-mer - Fold 3: ACC=0.8788, SN=0.7838, SP=0.9732, MCC=0.7713, AUC=0.9011\n",
      "Validation 6-mer - Fold 4: ACC=0.8586, SN=0.7730, SP=0.9359, MCC=0.7224, AUC=0.8774\n",
      "Validation 6-mer - Fold 5: ACC=0.9091, SN=0.8506, SP=0.9720, MCC=0.8255, AUC=0.9119\n",
      "Validation 6-mer - Fold 6: ACC=0.8653, SN=0.7962, SP=0.9429, MCC=0.7419, AUC=0.8868\n",
      "Validation 6-mer - Fold 7: ACC=0.8923, SN=0.8085, SP=0.9679, MCC=0.7912, AUC=0.9288\n",
      "Validation 6-mer - Fold 8: ACC=0.8687, SN=0.7945, SP=0.9404, MCC=0.7442, AUC=0.8923\n",
      "Validation 6-mer - Fold 9: ACC=0.8953, SN=0.8156, SP=0.9677, MCC=0.7969, AUC=0.9068\n",
      "Validation 6-mer - Fold 10: ACC=0.8514, SN=0.7500, SP=0.9773, MCC=0.7311, AUC=0.8938\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.50\n",
    "num_folds = 10\n",
    "kmer_values = [3, 4, 5, 6]\n",
    "model_date = \"2025-02-27\"\n",
    "train_predictions_list, test_predictions_list = [], []\n",
    "train_labels_list, test_labels_list = [], []\n",
    "\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Identifier model date: {model_date}\")\n",
    "print(f\"Number of folds: {num_folds}\\n\")\n",
    "\n",
    "results = []\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)  \n",
    "\n",
    "for kmer in kmer_values:\n",
    "    args.model_path = f\"./outputs/identifier_models/{model_date}/{kmer}-mer\"\n",
    "    args.train_data_path = f\"./data/enhancer_identification/{kmer}-mer_identification_train.txt\"\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(args, validation=False)\n",
    "    dataset_size = len(dataset)\n",
    "    dataset_indices = np.arange(dataset_size)\n",
    "\n",
    "    print(f\"Processing {kmer}-mer:\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset_indices)): \n",
    "        # Create train and validation subsets\n",
    "        train_subset = [dataset[i] for i in train_idx]\n",
    "        val_subset = [dataset[i] for i in val_idx]\n",
    "\n",
    "        # Create data loaders\n",
    "        train_dataloader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=False)\n",
    "        val_dataloader = DataLoader(val_subset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "        # Model\n",
    "        model = BertCustomBinaryClassifier.from_pretrained(args.model_path, num_labels=1).to(device)\n",
    "\n",
    "        # Train dataset prediction\n",
    "        train_predictions, train_labels = make_predictions(model, train_dataloader, kmer=kmer)\n",
    "        train_predictions_list.append(train_predictions)\n",
    "        train_labels_list.append(train_labels)\n",
    "\n",
    "        acc, sn, sp, mcc, auc = evaluate_metrics(train_predictions, train_labels)\n",
    "        results.append({\"k-mer\": kmer, \"Fold\": fold + 1, \"Dataset\": \"Train\", \n",
    "                        \"Accuracy\": acc, \"Sensitivity\": sn, \"Specificity\": sp, \"MCC\": mcc, \"AUC\": auc})\n",
    "        \n",
    "        # Validation dataset prediction\n",
    "        val_predictions, val_labels = make_predictions(model, val_dataloader, kmer=kmer)\n",
    "        test_predictions_list.append(val_predictions)\n",
    "        test_labels_list.append(val_labels)\n",
    "\n",
    "        acc, sn, sp, mcc, auc = evaluate_metrics(val_predictions, val_labels)\n",
    "        results.append({\"k-mer\": kmer, \"Fold\": fold + 1, \"Dataset\": \"Validation\", \n",
    "                        \"Accuracy\": acc, \"Sensitivity\": sn, \"Specificity\": sp, \"MCC\": mcc, \"AUC\": auc})\n",
    "        \n",
    "        print(f\"Validation {kmer}-mer - Fold {fold + 1}: ACC={acc:.4f}, SN={sn:.4f}, SP={sp:.4f}, MCC={mcc:.4f}, AUC={auc:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_10_df = pd.DataFrame(results, columns=[\"k-mer\", \"Dataset\", \"Fold\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"MCC\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold training results:\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset   |   Fold |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+===========+========+============+===============+===============+========+========+\n",
      "|       3 | Train     |      1 |     0.9023 |        0.8510 |        0.9536 | 0.8088 | 0.9045 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      2 |     0.8989 |        0.8493 |        0.9489 | 0.8019 | 0.9005 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      3 |     0.9019 |        0.8510 |        0.9528 | 0.8080 | 0.9041 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      4 |     0.9019 |        0.8503 |        0.9541 | 0.8084 | 0.9028 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      5 |     0.8963 |        0.8406 |        0.9515 | 0.7973 | 0.8982 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      6 |     0.9000 |        0.8470 |        0.9524 | 0.8043 | 0.9035 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      7 |     0.8982 |        0.8436 |        0.9533 | 0.8014 | 0.8987 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      8 |     0.8985 |        0.8438 |        0.9535 | 0.8020 | 0.8998 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      9 |     0.8990 |        0.8481 |        0.9503 | 0.8023 | 0.8996 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |     10 |     0.9023 |        0.8523 |        0.9512 | 0.8082 | 0.9037 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      1 |     0.9086 |        0.8533 |        0.9640 | 0.8224 | 0.9201 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      2 |     0.9075 |        0.8507 |        0.9647 | 0.8205 | 0.9176 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      3 |     0.9057 |        0.8503 |        0.9610 | 0.8163 | 0.9158 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      4 |     0.9098 |        0.8541 |        0.9661 | 0.8249 | 0.9185 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      5 |     0.9060 |        0.8496 |        0.9620 | 0.8171 | 0.9178 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      6 |     0.9075 |        0.8508 |        0.9635 | 0.8200 | 0.9192 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      7 |     0.9038 |        0.8459 |        0.9623 | 0.8133 | 0.9146 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      8 |     0.9045 |        0.8468 |        0.9625 | 0.8146 | 0.9157 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      9 |     0.9046 |        0.8474 |        0.9624 | 0.8147 | 0.9174 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |     10 |     0.9087 |        0.8553 |        0.9608 | 0.8215 | 0.9176 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      1 |     0.8836 |        0.8196 |        0.9476 | 0.7735 | 0.9065 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      2 |     0.8847 |        0.8216 |        0.9482 | 0.7758 | 0.9089 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      3 |     0.8854 |        0.8249 |        0.9461 | 0.7766 | 0.9090 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      4 |     0.8862 |        0.8235 |        0.9495 | 0.7789 | 0.9122 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      5 |     0.8843 |        0.8218 |        0.9463 | 0.7744 | 0.9078 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      6 |     0.8866 |        0.8267 |        0.9457 | 0.7783 | 0.9109 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      7 |     0.8832 |        0.8198 |        0.9473 | 0.7730 | 0.9053 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      8 |     0.8854 |        0.8244 |        0.9467 | 0.7768 | 0.9069 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      9 |     0.8814 |        0.8176 |        0.9458 | 0.7693 | 0.9067 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |     10 |     0.8870 |        0.8280 |        0.9445 | 0.7787 | 0.9090 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      1 |     0.8776 |        0.7994 |        0.9558 | 0.7646 | 0.8976 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      2 |     0.8753 |        0.7948 |        0.9564 | 0.7609 | 0.8976 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      3 |     0.8753 |        0.7994 |        0.9513 | 0.7595 | 0.8957 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      4 |     0.8776 |        0.8004 |        0.9556 | 0.7648 | 0.8984 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      5 |     0.8720 |        0.7917 |        0.9515 | 0.7533 | 0.8944 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      6 |     0.8768 |        0.7980 |        0.9546 | 0.7626 | 0.8972 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      7 |     0.8738 |        0.7967 |        0.9518 | 0.7572 | 0.8927 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      8 |     0.8765 |        0.7982 |        0.9550 | 0.7625 | 0.8967 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      9 |     0.8735 |        0.7960 |        0.9518 | 0.7566 | 0.8952 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |     10 |     0.8784 |        0.8038 |        0.9512 | 0.7643 | 0.8969 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "training_10_df = results_10_df[results_10_df['Dataset'].str.contains(\"Train\")]\n",
    "print(f\"{num_folds}-fold training results:\")\n",
    "print(tabulate(training_10_df, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold validation results:\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset    |   Fold |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+============+========+============+===============+===============+========+========+\n",
      "|       3 | Validation |      1 |     0.8788 |        0.8176 |        0.9396 | 0.7631 | 0.8754 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      2 |     0.9091 |        0.8333 |        0.9804 | 0.8256 | 0.9107 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      3 |     0.8822 |        0.8176 |        0.9463 | 0.7705 | 0.8786 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      4 |     0.8822 |        0.8227 |        0.9359 | 0.7665 | 0.8908 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      5 |     0.9327 |        0.9091 |        0.9580 | 0.8667 | 0.9312 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      6 |     0.8990 |        0.8535 |        0.9500 | 0.8032 | 0.8830 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      7 |     0.9158 |        0.8865 |        0.9423 | 0.8317 | 0.9302 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      8 |     0.9125 |        0.8836 |        0.9404 | 0.8259 | 0.9184 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      9 |     0.9088 |        0.8440 |        0.9677 | 0.8217 | 0.9192 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |     10 |     0.8784 |        0.8110 |        0.9621 | 0.7703 | 0.8864 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      1 |     0.8889 |        0.8243 |        0.9530 | 0.7841 | 0.8926 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      2 |     0.8990 |        0.8472 |        0.9477 | 0.8008 | 0.9158 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      3 |     0.9158 |        0.8514 |        0.9799 | 0.8385 | 0.9328 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      4 |     0.8788 |        0.8156 |        0.9359 | 0.7601 | 0.9077 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      5 |     0.9125 |        0.8571 |        0.9720 | 0.8316 | 0.9139 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      6 |     0.8990 |        0.8471 |        0.9571 | 0.8046 | 0.9012 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      7 |     0.9327 |        0.8936 |        0.9679 | 0.8665 | 0.9436 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      8 |     0.9259 |        0.8836 |        0.9669 | 0.8544 | 0.9341 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      9 |     0.9257 |        0.8794 |        0.9677 | 0.8533 | 0.9150 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |     10 |     0.8885 |        0.8110 |        0.9848 | 0.7942 | 0.9175 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      1 |     0.8956 |        0.8514 |        0.9396 | 0.7942 | 0.9247 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      2 |     0.8855 |        0.8333 |        0.9346 | 0.7736 | 0.9038 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      3 |     0.8788 |        0.8041 |        0.9530 | 0.7659 | 0.9025 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      4 |     0.8721 |        0.8156 |        0.9231 | 0.7456 | 0.8733 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      5 |     0.8889 |        0.8312 |        0.9510 | 0.7849 | 0.9141 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      6 |     0.8687 |        0.7898 |        0.9571 | 0.7516 | 0.8882 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      7 |     0.8990 |        0.8511 |        0.9423 | 0.7993 | 0.9361 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      8 |     0.8788 |        0.8082 |        0.9470 | 0.7640 | 0.9228 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      9 |     0.9155 |        0.8723 |        0.9548 | 0.8324 | 0.9230 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |     10 |     0.8649 |        0.7805 |        0.9697 | 0.7502 | 0.9058 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      1 |     0.8586 |        0.7838 |        0.9329 | 0.7250 | 0.8826 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      2 |     0.8788 |        0.8264 |        0.9281 | 0.7601 | 0.8857 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      3 |     0.8788 |        0.7838 |        0.9732 | 0.7713 | 0.9011 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      4 |     0.8586 |        0.7730 |        0.9359 | 0.7224 | 0.8774 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      5 |     0.9091 |        0.8506 |        0.9720 | 0.8255 | 0.9119 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      6 |     0.8653 |        0.7962 |        0.9429 | 0.7419 | 0.8868 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      7 |     0.8923 |        0.8085 |        0.9679 | 0.7912 | 0.9288 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      8 |     0.8687 |        0.7945 |        0.9404 | 0.7442 | 0.8923 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      9 |     0.8953 |        0.8156 |        0.9677 | 0.7969 | 0.9068 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |     10 |     0.8514 |        0.7500 |        0.9773 | 0.7311 | 0.8938 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "validation_10_df = results_10_df[results_10_df['Dataset'].str.contains(\"Validation\")]\n",
    "print(f\"{num_folds}-fold validation results:\")\n",
    "print(tabulate(validation_10_df, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 10-fold training results:\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset   |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+===========+============+===============+===============+========+========+\n",
      "|       3 | Train     |     0.8999 |        0.8477 |        0.9522 | 0.8043 | 0.9015 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |     0.9067 |        0.8504 |        0.9629 | 0.8185 | 0.9174 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |     0.8848 |        0.8228 |        0.9468 | 0.7755 | 0.9083 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |     0.8757 |        0.7978 |        0.9535 | 0.7606 | 0.8963 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "\n",
      "Average 10-fold validation results:\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset    |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+============+============+===============+===============+========+========+\n",
      "|       3 | Validation |     0.8999 |        0.8479 |        0.9523 | 0.8045 | 0.9024 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |     0.9067 |        0.8510 |        0.9633 | 0.8188 | 0.9174 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |     0.8848 |        0.8237 |        0.9472 | 0.7762 | 0.9094 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |     0.8757 |        0.7982 |        0.9538 | 0.7610 | 0.8967 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate average metrics for each k-mer across the k folds\n",
    "average_10_results = results_10_df.groupby(['k-mer', 'Dataset']).mean(numeric_only=True).reset_index()\n",
    "average_10_results = average_10_results.drop(columns=['Fold'])\n",
    "\n",
    "average_training_10_results = average_10_results[average_10_results['Dataset'].str.contains(\"Train\")]\n",
    "average_validation_10_results = average_10_results[average_10_results['Dataset'].str.contains(\"Validation\")]\n",
    "\n",
    "print(f\"Average {num_folds}-fold training results:\")\n",
    "print(tabulate(average_training_10_results, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))\n",
    "\n",
    "print(f\"\\nAverage {num_folds}-fold validation results:\")\n",
    "print(tabulate(average_validation_10_results, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
