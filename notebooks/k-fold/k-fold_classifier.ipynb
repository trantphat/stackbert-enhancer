{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from model import BertCustomBinaryClassifier\n",
    "from utils.ensemble_utils import make_predictions\n",
    "from utils.evaluate_metrics import evaluate_metrics\n",
    "from utils.data_preprocessing import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"transforkmer_values.modeling_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"\")\n",
    "parser.add_argument(\"--max_length\", type=int, default=200, help=\"\")\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5-fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5\n",
      "Classifier model date: 2025-02-27\n",
      "Number of folds: 5\n",
      "\n",
      "Processing 3-mer:\n",
      "Validation 3-mer - Fold 1: ACC=0.8418, SN=0.7683, SP=0.9323, MCC=0.6997, AUC=0.8790\n",
      "Validation 3-mer - Fold 2: ACC=0.9057, SN=0.8284, SP=0.9693, MCC=0.8136, AUC=0.9346\n",
      "Validation 3-mer - Fold 3: ACC=0.8990, SN=0.8582, SP=0.9359, MCC=0.7986, AUC=0.9086\n",
      "Validation 3-mer - Fold 4: ACC=0.8956, SN=0.8298, SP=0.9551, MCC=0.7948, AUC=0.9309\n",
      "Validation 3-mer - Fold 5: ACC=0.9020, SN=0.8704, SP=0.9403, MCC=0.8071, AUC=0.9338\n",
      "\n",
      "\n",
      "Processing 4-mer:\n",
      "Validation 4-mer - Fold 1: ACC=0.8822, SN=0.8354, SP=0.9398, MCC=0.7712, AUC=0.8938\n",
      "Validation 4-mer - Fold 2: ACC=0.9428, SN=0.9030, SP=0.9755, MCC=0.8854, AUC=0.9649\n",
      "Validation 4-mer - Fold 3: ACC=0.9024, SN=0.8582, SP=0.9423, MCC=0.8057, AUC=0.8990\n",
      "Validation 4-mer - Fold 4: ACC=0.9192, SN=0.8511, SP=0.9808, MCC=0.8433, AUC=0.9330\n",
      "Validation 4-mer - Fold 5: ACC=0.9088, SN=0.8765, SP=0.9478, MCC=0.8206, AUC=0.9180\n",
      "\n",
      "\n",
      "Processing 5-mer:\n",
      "Validation 5-mer - Fold 1: ACC=0.8519, SN=0.7683, SP=0.9549, MCC=0.7237, AUC=0.8481\n",
      "Validation 5-mer - Fold 2: ACC=0.9360, SN=0.8806, SP=0.9816, MCC=0.8732, AUC=0.9302\n",
      "Validation 5-mer - Fold 3: ACC=0.9091, SN=0.8582, SP=0.9551, MCC=0.8201, AUC=0.9094\n",
      "Validation 5-mer - Fold 4: ACC=0.8956, SN=0.8085, SP=0.9744, MCC=0.7989, AUC=0.8910\n",
      "Validation 5-mer - Fold 5: ACC=0.8986, SN=0.8580, SP=0.9478, MCC=0.8022, AUC=0.8972\n",
      "\n",
      "\n",
      "Processing 6-mer:\n",
      "Validation 6-mer - Fold 1: ACC=0.8754, SN=0.8049, SP=0.9624, MCC=0.7654, AUC=0.8865\n",
      "Validation 6-mer - Fold 2: ACC=0.9360, SN=0.8806, SP=0.9816, MCC=0.8732, AUC=0.9177\n",
      "Validation 6-mer - Fold 3: ACC=0.9057, SN=0.8582, SP=0.9487, MCC=0.8129, AUC=0.9033\n",
      "Validation 6-mer - Fold 4: ACC=0.9158, SN=0.8369, SP=0.9872, MCC=0.8386, AUC=0.8917\n",
      "Validation 6-mer - Fold 5: ACC=0.8885, SN=0.8395, SP=0.9478, MCC=0.7842, AUC=0.8907\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.50\n",
    "num_folds = 5\n",
    "kmer_values = [3, 4, 5, 6]\n",
    "model_date = \"2025-02-27_V1\"\n",
    "train_predictions_list, test_predictions_list = [], []\n",
    "train_labels_list, test_labels_list = [], []\n",
    "\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Classifier model date: {model_date}\")\n",
    "print(f\"Number of folds: {num_folds}\\n\")\n",
    "\n",
    "results = []\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)  \n",
    "\n",
    "for kmer in kmer_values:\n",
    "    args.model_path = f\"./outputs/classifier_models/{model_date}/{kmer}-mer\"\n",
    "    args.train_data_path = f\"./data/enhancer_classification/{kmer}-mer_classification_train.txt\"\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(args, validation=False)\n",
    "    dataset_size = len(dataset)\n",
    "    dataset_indices = np.arange(dataset_size)\n",
    "\n",
    "    print(f\"Processing {kmer}-mer:\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset_indices)): \n",
    "        # Create train and validation subsets\n",
    "        train_subset = [dataset[i] for i in train_idx]\n",
    "        val_subset = [dataset[i] for i in val_idx]\n",
    "\n",
    "        # Create data loaders\n",
    "        train_dataloader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=False)\n",
    "        val_dataloader = DataLoader(val_subset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "        # Model\n",
    "        model = BertCustomBinaryClassifier.from_pretrained(args.model_path, num_labels=1).to(device)\n",
    "\n",
    "        # Train dataset prediction\n",
    "        train_predictions, train_labels = make_predictions(model, train_dataloader, kmer=kmer)\n",
    "        train_predictions_list.append(train_predictions)\n",
    "        train_labels_list.append(train_labels)\n",
    "\n",
    "        acc, sn, sp, mcc, auc = evaluate_metrics(train_predictions, train_labels)\n",
    "        results.append({\"k-mer\": kmer, \"Fold\": fold + 1, \"Dataset\": \"Train\", \n",
    "                        \"Accuracy\": acc, \"Sensitivity\": sn, \"Specificity\": sp, \"MCC\": mcc, \"AUC\": auc})\n",
    "        \n",
    "        # Validation dataset prediction\n",
    "        val_predictions, val_labels = make_predictions(model, val_dataloader, kmer=kmer)\n",
    "        test_predictions_list.append(val_predictions)\n",
    "        test_labels_list.append(val_labels)\n",
    "\n",
    "        acc, sn, sp, mcc, auc = evaluate_metrics(val_predictions, val_labels)\n",
    "        results.append({\"k-mer\": kmer, \"Fold\": fold + 1, \"Dataset\": \"Validation\", \n",
    "                        \"Accuracy\": acc, \"Sensitivity\": sn, \"Specificity\": sp, \"MCC\": mcc, \"AUC\": auc})\n",
    "        \n",
    "        print(f\"Validation {kmer}-mer - Fold {fold + 1}: ACC={acc:.4f}, SN={sn:.4f}, SP={sp:.4f}, MCC={mcc:.4f}, AUC={auc:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_5_df = pd.DataFrame(results, columns=[\"k-mer\", \"Dataset\", \"Fold\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"MCC\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold training results:\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset   |   Fold |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+===========+========+============+===============+===============+========+========+\n",
      "|       3 | Train     |      1 |     0.9006 |        0.8478 |        0.9507 | 0.8044 | 0.9267 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      2 |     0.8846 |        0.8306 |        0.9413 | 0.7749 | 0.9119 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      3 |     0.8863 |        0.8236 |        0.9505 | 0.7794 | 0.9184 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      4 |     0.8871 |        0.8303 |        0.9454 | 0.7800 | 0.9125 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      5 |     0.8855 |        0.8190 |        0.9490 | 0.7763 | 0.9120 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      1 |     0.9183 |        0.8720 |        0.9622 | 0.8392 | 0.9294 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      2 |     0.9031 |        0.8553 |        0.9534 | 0.8109 | 0.9109 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      3 |     0.9132 |        0.8652 |        0.9625 | 0.8307 | 0.9279 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      4 |     0.9090 |        0.8669 |        0.9522 | 0.8214 | 0.9188 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      5 |     0.9116 |        0.8603 |        0.9605 | 0.8266 | 0.9221 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      1 |     0.9099 |        0.8512 |        0.9655 | 0.8241 | 0.9073 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      2 |     0.8888 |        0.8224 |        0.9585 | 0.7861 | 0.8860 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      3 |     0.8955 |        0.8270 |        0.9659 | 0.7994 | 0.8909 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      4 |     0.8989 |        0.8386 |        0.9608 | 0.8044 | 0.8949 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      5 |     0.8981 |        0.8259 |        0.9671 | 0.8031 | 0.8930 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      1 |     0.9115 |        0.8529 |        0.9672 | 0.8275 | 0.9021 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      2 |     0.8964 |        0.8339 |        0.9620 | 0.8004 | 0.8940 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      3 |     0.9040 |        0.8386 |        0.9710 | 0.8156 | 0.8976 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      4 |     0.9014 |        0.8436 |        0.9608 | 0.8089 | 0.8998 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      5 |     0.9082 |        0.8431 |        0.9704 | 0.8221 | 0.8999 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "training_5_df = results_5_df[results_5_df['Dataset'].str.contains(\"Train\")]\n",
    "print(f\"{num_folds}-fold training results:\")\n",
    "print(tabulate(training_5_df, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation results:\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset    |   Fold |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+============+========+============+===============+===============+========+========+\n",
      "|       3 | Validation |      1 |     0.8418 |        0.7683 |        0.9323 | 0.6997 | 0.8790 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      2 |     0.9057 |        0.8284 |        0.9693 | 0.8136 | 0.9346 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      3 |     0.8990 |        0.8582 |        0.9359 | 0.7986 | 0.9086 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      4 |     0.8956 |        0.8298 |        0.9551 | 0.7948 | 0.9309 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      5 |     0.9020 |        0.8704 |        0.9403 | 0.8071 | 0.9338 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      1 |     0.8822 |        0.8354 |        0.9398 | 0.7712 | 0.8938 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      2 |     0.9428 |        0.9030 |        0.9755 | 0.8854 | 0.9649 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      3 |     0.9024 |        0.8582 |        0.9423 | 0.8057 | 0.8990 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      4 |     0.9192 |        0.8511 |        0.9808 | 0.8433 | 0.9330 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      5 |     0.9088 |        0.8765 |        0.9478 | 0.8206 | 0.9180 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      1 |     0.8519 |        0.7683 |        0.9549 | 0.7237 | 0.8481 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      2 |     0.9360 |        0.8806 |        0.9816 | 0.8732 | 0.9302 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      3 |     0.9091 |        0.8582 |        0.9551 | 0.8201 | 0.9094 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      4 |     0.8956 |        0.8085 |        0.9744 | 0.7989 | 0.8910 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      5 |     0.8986 |        0.8580 |        0.9478 | 0.8022 | 0.8972 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      1 |     0.8754 |        0.8049 |        0.9624 | 0.7654 | 0.8865 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      2 |     0.9360 |        0.8806 |        0.9816 | 0.8732 | 0.9177 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      3 |     0.9057 |        0.8582 |        0.9487 | 0.8129 | 0.9033 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      4 |     0.9158 |        0.8369 |        0.9872 | 0.8386 | 0.8917 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      5 |     0.8885 |        0.8395 |        0.9478 | 0.7842 | 0.8907 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "validation_5_df = results_5_df[results_5_df['Dataset'].str.contains(\"Validation\")]\n",
    "print(f\"{num_folds}-fold validation results:\")\n",
    "print(tabulate(validation_5_df, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-fold training results:\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset   |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+===========+============+===============+===============+========+========+\n",
      "|       3 | Train     |     0.8888 |        0.8302 |        0.9474 | 0.7830 | 0.9163 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |     0.9111 |        0.8639 |        0.9582 | 0.8258 | 0.9218 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |     0.8982 |        0.8330 |        0.9636 | 0.8034 | 0.8944 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |     0.9043 |        0.8424 |        0.9663 | 0.8149 | 0.8987 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "\n",
      "Average 5-fold validation results:\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset    |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+============+============+===============+===============+========+========+\n",
      "|       3 | Validation |     0.8888 |        0.8310 |        0.9466 | 0.7828 | 0.9174 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |     0.9110 |        0.8648 |        0.9572 | 0.8252 | 0.9217 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |     0.8982 |        0.8347 |        0.9627 | 0.8036 | 0.8952 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |     0.9043 |        0.8440 |        0.9655 | 0.8148 | 0.8980 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate average metrics for each k-mer across the k folds\n",
    "average_5_results = results_5_df.groupby(['k-mer', 'Dataset']).mean(numeric_only=True).reset_index()\n",
    "average_5_results = average_5_results.drop(columns=['Fold'])\n",
    "\n",
    "average_training_5_results = average_5_results[average_5_results['Dataset'].str.contains(\"Train\")]\n",
    "average_validation_5_results = average_5_results[average_5_results['Dataset'].str.contains(\"Validation\")]\n",
    "\n",
    "print(f\"Average {num_folds}-fold training results:\")\n",
    "print(tabulate(average_training_5_results, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))\n",
    "\n",
    "print(f\"\\nAverage {num_folds}-fold validation results:\")\n",
    "print(tabulate(average_validation_5_results, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10-fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5\n",
      "Classifier model date: 2025-02-27\n",
      "Number of folds: 10\n",
      "\n",
      "Processing 3-mer:\n",
      "Validation 3-mer - Fold 1: ACC=0.8456, SN=0.7750, SP=0.9275, MCC=0.7042, AUC=0.8964\n",
      "Validation 3-mer - Fold 2: ACC=0.8389, SN=0.7619, SP=0.9385, MCC=0.6973, AUC=0.8595\n",
      "Validation 3-mer - Fold 3: ACC=0.8993, SN=0.8281, SP=0.9529, MCC=0.7955, AUC=0.9208\n",
      "Validation 3-mer - Fold 4: ACC=0.9128, SN=0.8333, SP=0.9870, MCC=0.8337, AUC=0.9518\n",
      "Validation 3-mer - Fold 5: ACC=0.9189, SN=0.8571, SP=0.9647, MCC=0.8351, AUC=0.9235\n",
      "Validation 3-mer - Fold 6: ACC=0.8784, SN=0.8553, SP=0.9028, MCC=0.7580, AUC=0.8862\n",
      "Validation 3-mer - Fold 7: ACC=0.8986, SN=0.8308, SP=0.9518, MCC=0.7956, AUC=0.9234\n",
      "Validation 3-mer - Fold 8: ACC=0.8919, SN=0.8289, SP=0.9583, MCC=0.7916, AUC=0.9368\n",
      "Validation 3-mer - Fold 9: ACC=0.8919, SN=0.8706, SP=0.9206, MCC=0.7842, AUC=0.9197\n",
      "Validation 3-mer - Fold 10: ACC=0.9122, SN=0.8701, SP=0.9577, MCC=0.8284, AUC=0.9493\n",
      "\n",
      "\n",
      "Processing 4-mer:\n",
      "Validation 4-mer - Fold 1: ACC=0.9060, SN=0.8375, SP=0.9855, MCC=0.8239, AUC=0.9260\n",
      "Validation 4-mer - Fold 2: ACC=0.8591, SN=0.8333, SP=0.8923, MCC=0.7201, AUC=0.8636\n",
      "Validation 4-mer - Fold 3: ACC=0.9396, SN=0.9062, SP=0.9647, MCC=0.8768, AUC=0.9515\n",
      "Validation 4-mer - Fold 4: ACC=0.9463, SN=0.9028, SP=0.9870, MCC=0.8951, AUC=0.9800\n",
      "Validation 4-mer - Fold 5: ACC=0.8986, SN=0.8413, SP=0.9412, MCC=0.7925, AUC=0.8989\n",
      "Validation 4-mer - Fold 6: ACC=0.9054, SN=0.8684, SP=0.9444, MCC=0.8138, AUC=0.9034\n",
      "Validation 4-mer - Fold 7: ACC=0.9392, SN=0.8615, SP=1.0000, MCC=0.8816, AUC=0.9249\n",
      "Validation 4-mer - Fold 8: ACC=0.8986, SN=0.8421, SP=0.9583, MCC=0.8038, AUC=0.9369\n",
      "Validation 4-mer - Fold 9: ACC=0.9257, SN=0.9059, SP=0.9524, MCC=0.8515, AUC=0.9281\n",
      "Validation 4-mer - Fold 10: ACC=0.8919, SN=0.8442, SP=0.9437, MCC=0.7890, AUC=0.9048\n",
      "\n",
      "\n",
      "Processing 5-mer:\n",
      "Validation 5-mer - Fold 1: ACC=0.8792, SN=0.8125, SP=0.9565, MCC=0.7699, AUC=0.8681\n",
      "Validation 5-mer - Fold 2: ACC=0.8255, SN=0.7262, SP=0.9538, MCC=0.6813, AUC=0.8244\n",
      "Validation 5-mer - Fold 3: ACC=0.9195, SN=0.8125, SP=1.0000, MCC=0.8438, AUC=0.8869\n",
      "Validation 5-mer - Fold 4: ACC=0.9530, SN=0.9444, SP=0.9610, MCC=0.9060, AUC=0.9674\n",
      "Validation 5-mer - Fold 5: ACC=0.9054, SN=0.8254, SP=0.9647, MCC=0.8084, AUC=0.9014\n",
      "Validation 5-mer - Fold 6: ACC=0.9122, SN=0.8816, SP=0.9444, MCC=0.8264, AUC=0.9110\n",
      "Validation 5-mer - Fold 7: ACC=0.9189, SN=0.8154, SP=1.0000, MCC=0.8440, AUC=0.9261\n",
      "Validation 5-mer - Fold 8: ACC=0.8716, SN=0.8026, SP=0.9444, MCC=0.7524, AUC=0.8564\n",
      "Validation 5-mer - Fold 9: ACC=0.8919, SN=0.8471, SP=0.9524, MCC=0.7906, AUC=0.9133\n",
      "Validation 5-mer - Fold 10: ACC=0.9054, SN=0.8701, SP=0.9437, MCC=0.8138, AUC=0.8830\n",
      "\n",
      "\n",
      "Processing 6-mer:\n",
      "Validation 6-mer - Fold 1: ACC=0.8993, SN=0.8500, SP=0.9565, MCC=0.8052, AUC=0.8907\n",
      "Validation 6-mer - Fold 2: ACC=0.8523, SN=0.7619, SP=0.9692, MCC=0.7299, AUC=0.8826\n",
      "Validation 6-mer - Fold 3: ACC=0.9396, SN=0.8750, SP=0.9882, MCC=0.8792, AUC=0.9246\n",
      "Validation 6-mer - Fold 4: ACC=0.9262, SN=0.8750, SP=0.9740, MCC=0.8555, AUC=0.8993\n",
      "Validation 6-mer - Fold 5: ACC=0.9122, SN=0.8730, SP=0.9412, MCC=0.8200, AUC=0.9010\n",
      "Validation 6-mer - Fold 6: ACC=0.9054, SN=0.8553, SP=0.9583, MCC=0.8160, AUC=0.9140\n",
      "Validation 6-mer - Fold 7: ACC=0.9189, SN=0.8308, SP=0.9880, MCC=0.8408, AUC=0.8791\n",
      "Validation 6-mer - Fold 8: ACC=0.9122, SN=0.8421, SP=0.9861, MCC=0.8341, AUC=0.9032\n",
      "Validation 6-mer - Fold 9: ACC=0.9122, SN=0.8706, SP=0.9683, MCC=0.8298, AUC=0.9259\n",
      "Validation 6-mer - Fold 10: ACC=0.8649, SN=0.8052, SP=0.9296, MCC=0.7375, AUC=0.8556\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.50\n",
    "num_folds = 10\n",
    "kmer_values = [3, 4, 5, 6]\n",
    "model_date = \"2025-02-27\"\n",
    "train_predictions_list, test_predictions_list = [], []\n",
    "train_labels_list, test_labels_list = [], []\n",
    "\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Classifier model date: {model_date}\")\n",
    "print(f\"Number of folds: {num_folds}\\n\")\n",
    "\n",
    "results = []\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)  \n",
    "\n",
    "for kmer in kmer_values:\n",
    "    args.model_path = f\"./outputs/classifier_models/{model_date}/{kmer}-mer\"\n",
    "    args.train_data_path = f\"./data/enhancer_classification/{kmer}-mer_classification_train.txt\"\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(args, validation=False)\n",
    "    dataset_size = len(dataset)\n",
    "    dataset_indices = np.arange(dataset_size)\n",
    "\n",
    "    print(f\"Processing {kmer}-mer:\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset_indices)): \n",
    "        # Create train and validation subsets\n",
    "        train_subset = [dataset[i] for i in train_idx]\n",
    "        val_subset = [dataset[i] for i in val_idx]\n",
    "\n",
    "        # Create data loaders\n",
    "        train_dataloader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=False)\n",
    "        val_dataloader = DataLoader(val_subset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "        # Model\n",
    "        model = BertCustomBinaryClassifier.from_pretrained(args.model_path, num_labels=1).to(device)\n",
    "\n",
    "        # Train dataset prediction\n",
    "        train_predictions, train_labels = make_predictions(model, train_dataloader, kmer=kmer)\n",
    "        train_predictions_list.append(train_predictions)\n",
    "        train_labels_list.append(train_labels)\n",
    "\n",
    "        acc, sn, sp, mcc, auc = evaluate_metrics(train_predictions, train_labels)\n",
    "        results.append({\"k-mer\": kmer, \"Fold\": fold + 1, \"Dataset\": \"Train\", \n",
    "                        \"Accuracy\": acc, \"Sensitivity\": sn, \"Specificity\": sp, \"MCC\": mcc, \"AUC\": auc})\n",
    "        \n",
    "        # Validation dataset prediction\n",
    "        val_predictions, val_labels = make_predictions(model, val_dataloader, kmer=kmer)\n",
    "        test_predictions_list.append(val_predictions)\n",
    "        test_labels_list.append(val_labels)\n",
    "\n",
    "        acc, sn, sp, mcc, auc = evaluate_metrics(val_predictions, val_labels)\n",
    "        results.append({\"k-mer\": kmer, \"Fold\": fold + 1, \"Dataset\": \"Validation\", \n",
    "                        \"Accuracy\": acc, \"Sensitivity\": sn, \"Specificity\": sp, \"MCC\": mcc, \"AUC\": auc})\n",
    "        \n",
    "        print(f\"Validation {kmer}-mer - Fold {fold + 1}: ACC={acc:.4f}, SN={sn:.4f}, SP={sp:.4f}, MCC={mcc:.4f}, AUC={auc:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_10_df = pd.DataFrame(results, columns=[\"k-mer\", \"Dataset\", \"Fold\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"MCC\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold training results:\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset   |   Fold |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+===========+========+============+===============+===============+========+========+\n",
      "|       3 | Train     |      1 |     0.8936 |        0.8369 |        0.9495 | 0.7919 | 0.9187 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      2 |     0.8944 |        0.8389 |        0.9483 | 0.7929 | 0.9229 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      3 |     0.8876 |        0.8304 |        0.9467 | 0.7813 | 0.9160 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      4 |     0.8861 |        0.8299 |        0.9429 | 0.7774 | 0.9124 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      5 |     0.8855 |        0.8277 |        0.9452 | 0.7771 | 0.9150 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      6 |     0.8900 |        0.8273 |        0.9522 | 0.7860 | 0.9193 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      7 |     0.8877 |        0.8301 |        0.9469 | 0.7814 | 0.9152 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      8 |     0.8885 |        0.8303 |        0.9463 | 0.7821 | 0.9141 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |      9 |     0.8885 |        0.8250 |        0.9499 | 0.7822 | 0.9158 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Train     |     10 |     0.8862 |        0.8256 |        0.9463 | 0.7779 | 0.9129 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      1 |     0.9116 |        0.8671 |        0.9554 | 0.8262 | 0.9217 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      2 |     0.9169 |        0.8678 |        0.9645 | 0.8372 | 0.9286 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      3 |     0.9079 |        0.8599 |        0.9574 | 0.8201 | 0.9186 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      4 |     0.9071 |        0.8597 |        0.9549 | 0.8181 | 0.9153 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      5 |     0.9124 |        0.8660 |        0.9604 | 0.8290 | 0.9250 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      6 |     0.9117 |        0.8634 |        0.9597 | 0.8271 | 0.9241 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      7 |     0.9079 |        0.8641 |        0.9530 | 0.8195 | 0.9210 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      8 |     0.9124 |        0.8664 |        0.9582 | 0.8283 | 0.9199 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |      9 |     0.9094 |        0.8584 |        0.9588 | 0.8224 | 0.9206 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |     10 |     0.9132 |        0.8662 |        0.9598 | 0.8299 | 0.9233 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      1 |     0.9004 |        0.8353 |        0.9643 | 0.8071 | 0.8981 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      2 |     0.9064 |        0.8465 |        0.9645 | 0.8179 | 0.9020 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      3 |     0.8959 |        0.8348 |        0.9589 | 0.7986 | 0.8946 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      4 |     0.8921 |        0.8209 |        0.9639 | 0.7926 | 0.8863 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      5 |     0.8975 |        0.8336 |        0.9635 | 0.8024 | 0.8935 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      6 |     0.8967 |        0.8273 |        0.9657 | 0.8010 | 0.8922 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      7 |     0.8960 |        0.8346 |        0.9590 | 0.7987 | 0.8909 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      8 |     0.9012 |        0.8363 |        0.9657 | 0.8091 | 0.8985 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |      9 |     0.8990 |        0.8311 |        0.9647 | 0.8043 | 0.8921 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |     10 |     0.8975 |        0.8286 |        0.9657 | 0.8023 | 0.8955 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      1 |     0.9049 |        0.8414 |        0.9673 | 0.8159 | 0.8996 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      2 |     0.9101 |        0.8526 |        0.9660 | 0.8250 | 0.9008 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      3 |     0.9004 |        0.8392 |        0.9635 | 0.8077 | 0.8956 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      4 |     0.9019 |        0.8388 |        0.9654 | 0.8104 | 0.8985 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      5 |     0.9034 |        0.8395 |        0.9696 | 0.8145 | 0.8989 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      6 |     0.9042 |        0.8408 |        0.9672 | 0.8148 | 0.8967 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      7 |     0.9027 |        0.8434 |        0.9636 | 0.8118 | 0.9002 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      8 |     0.9034 |        0.8423 |        0.9642 | 0.8128 | 0.8982 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |      9 |     0.9034 |        0.8387 |        0.9661 | 0.8128 | 0.8952 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |     10 |     0.9087 |        0.8466 |        0.9702 | 0.8235 | 0.9034 |\n",
      "+---------+-----------+--------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "training_10_df = results_10_df[results_10_df['Dataset'].str.contains(\"Train\")]\n",
    "print(f\"{num_folds}-fold training results:\")\n",
    "print(tabulate(training_10_df, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold validation results:\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset    |   Fold |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+============+========+============+===============+===============+========+========+\n",
      "|       3 | Validation |      1 |     0.8456 |        0.7750 |        0.9275 | 0.7042 | 0.8964 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      2 |     0.8389 |        0.7619 |        0.9385 | 0.6973 | 0.8595 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      3 |     0.8993 |        0.8281 |        0.9529 | 0.7955 | 0.9208 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      4 |     0.9128 |        0.8333 |        0.9870 | 0.8337 | 0.9518 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      5 |     0.9189 |        0.8571 |        0.9647 | 0.8351 | 0.9235 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      6 |     0.8784 |        0.8553 |        0.9028 | 0.7580 | 0.8862 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      7 |     0.8986 |        0.8308 |        0.9518 | 0.7956 | 0.9234 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      8 |     0.8919 |        0.8289 |        0.9583 | 0.7916 | 0.9368 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |      9 |     0.8919 |        0.8706 |        0.9206 | 0.7842 | 0.9197 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       3 | Validation |     10 |     0.9122 |        0.8701 |        0.9577 | 0.8284 | 0.9493 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      1 |     0.9060 |        0.8375 |        0.9855 | 0.8239 | 0.9260 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      2 |     0.8591 |        0.8333 |        0.8923 | 0.7201 | 0.8636 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      3 |     0.9396 |        0.9062 |        0.9647 | 0.8768 | 0.9515 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      4 |     0.9463 |        0.9028 |        0.9870 | 0.8951 | 0.9800 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      5 |     0.8986 |        0.8413 |        0.9412 | 0.7925 | 0.8989 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      6 |     0.9054 |        0.8684 |        0.9444 | 0.8138 | 0.9034 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      7 |     0.9392 |        0.8615 |        1.0000 | 0.8816 | 0.9249 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      8 |     0.8986 |        0.8421 |        0.9583 | 0.8038 | 0.9369 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |      9 |     0.9257 |        0.9059 |        0.9524 | 0.8515 | 0.9281 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |     10 |     0.8919 |        0.8442 |        0.9437 | 0.7890 | 0.9048 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      1 |     0.8792 |        0.8125 |        0.9565 | 0.7699 | 0.8681 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      2 |     0.8255 |        0.7262 |        0.9538 | 0.6813 | 0.8244 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      3 |     0.9195 |        0.8125 |        1.0000 | 0.8438 | 0.8869 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      4 |     0.9530 |        0.9444 |        0.9610 | 0.9060 | 0.9674 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      5 |     0.9054 |        0.8254 |        0.9647 | 0.8084 | 0.9014 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      6 |     0.9122 |        0.8816 |        0.9444 | 0.8264 | 0.9110 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      7 |     0.9189 |        0.8154 |        1.0000 | 0.8440 | 0.9261 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      8 |     0.8716 |        0.8026 |        0.9444 | 0.7524 | 0.8564 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |      9 |     0.8919 |        0.8471 |        0.9524 | 0.7906 | 0.9133 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |     10 |     0.9054 |        0.8701 |        0.9437 | 0.8138 | 0.8830 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      1 |     0.8993 |        0.8500 |        0.9565 | 0.8052 | 0.8907 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      2 |     0.8523 |        0.7619 |        0.9692 | 0.7299 | 0.8826 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      3 |     0.9396 |        0.8750 |        0.9882 | 0.8792 | 0.9246 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      4 |     0.9262 |        0.8750 |        0.9740 | 0.8555 | 0.8993 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      5 |     0.9122 |        0.8730 |        0.9412 | 0.8200 | 0.9010 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      6 |     0.9054 |        0.8553 |        0.9583 | 0.8160 | 0.9140 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      7 |     0.9189 |        0.8308 |        0.9880 | 0.8408 | 0.8791 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      8 |     0.9122 |        0.8421 |        0.9861 | 0.8341 | 0.9032 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |      9 |     0.9122 |        0.8706 |        0.9683 | 0.8298 | 0.9259 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |     10 |     0.8649 |        0.8052 |        0.9296 | 0.7375 | 0.8556 |\n",
      "+---------+------------+--------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "validation_10_df = results_10_df[results_10_df['Dataset'].str.contains(\"Validation\")]\n",
    "print(f\"{num_folds}-fold validation results:\")\n",
    "print(tabulate(validation_10_df, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 10-fold training results:\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset   |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+===========+============+===============+===============+========+========+\n",
      "|       3 | Train     |     0.8888 |        0.8302 |        0.9474 | 0.7830 | 0.9162 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Train     |     0.9111 |        0.8639 |        0.9582 | 0.8258 | 0.9218 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Train     |     0.8982 |        0.8329 |        0.9636 | 0.8034 | 0.8944 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Train     |     0.9043 |        0.8423 |        0.9663 | 0.8149 | 0.8987 |\n",
      "+---------+-----------+------------+---------------+---------------+--------+--------+\n",
      "\n",
      "Average 10-fold validation results:\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|   k-mer | Dataset    |   Accuracy |   Sensitivity |   Specificity |    MCC |    AUC |\n",
      "+=========+============+============+===============+===============+========+========+\n",
      "|       3 | Validation |     0.8889 |        0.8311 |        0.9462 | 0.7824 | 0.9168 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       4 | Validation |     0.9110 |        0.8643 |        0.9570 | 0.8248 | 0.9218 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       5 | Validation |     0.8983 |        0.8338 |        0.9621 | 0.8037 | 0.8938 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n",
      "|       6 | Validation |     0.9043 |        0.8439 |        0.9659 | 0.8148 | 0.8976 |\n",
      "+---------+------------+------------+---------------+---------------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Calculate average metrics for each k-mer across the k folds\n",
    "average_10_results = results_10_df.groupby(['k-mer', 'Dataset']).mean(numeric_only=True).reset_index()\n",
    "average_10_results = average_10_results.drop(columns=['Fold'])\n",
    "\n",
    "average_training_10_results = average_10_results[average_10_results['Dataset'].str.contains(\"Train\")]\n",
    "average_validation_10_results = average_10_results[average_10_results['Dataset'].str.contains(\"Validation\")]\n",
    "\n",
    "print(f\"Average {num_folds}-fold training results:\")\n",
    "print(tabulate(average_training_10_results, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))\n",
    "\n",
    "print(f\"\\nAverage {num_folds}-fold validation results:\")\n",
    "print(tabulate(average_validation_10_results, headers=\"keys\", tablefmt=\"grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
