# DNABERT Pre-trained Models

DNABERT is a pre-trained NLP model for DNA sequences. For detailed information on the model architecture, training, and usage, please refer to the official repository and publication.

- **Official GitHub Repository:** [https://github.com/jerryji1993/DNABERT](https://github.com/jerryji1993/DNABERT)
- **Paper:** [DNABERT: pre-trained Bidirectional Encoder Representations from Transformers for DNA-language in genome](https://academic.oup.com/bioinformatics/article/37/15/2112/6128682)

